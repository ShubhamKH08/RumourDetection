{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b54d073e6b2f89c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2126cfcbcfdd081e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:37:10.083802Z",
     "start_time": "2024-05-22T05:37:08.503345Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e72f9754cf8282",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5d028cb6e9915",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## PHEME Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c7ce99da3830a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:27:59.162261Z",
     "start_time": "2024-05-22T15:27:59.152665Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pheme_dir = 'data/pheme-rnr-dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336bca93ca25a3c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Credbank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3126575474095871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:10:55.954117Z",
     "start_time": "2024-05-22T05:10:55.950834Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "search_tweets_path = 'data/credbank-dataset/cred_event_SearchTweets.data'\n",
    "turk_ratings_path = 'data/credbank-dataset/cred_event_TurkRatings.data'\n",
    "annotations_path = 'data/credbank-dataset/eventNonEvent_annotations.data'\n",
    "stream_tweets_path = 'data/credbank-dataset/stream_tweets_byTimestamp.data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e1c4bdce9e7e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Import the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2cad06-d44f-4274-af3a-888421e570bb",
   "metadata": {},
   "source": [
    "## PHEME Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca74718bfa83988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:10:55.964457Z",
     "start_time": "2024-05-22T05:10:55.955632Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def load_pheme_dataset(base_dir):\n",
    "    data = []\n",
    "    subdirs = ['rumours', 'non-rumours']\n",
    "\n",
    "    for event in os.listdir(base_dir):\n",
    "        for subdir in subdirs:\n",
    "            event_dir = os.path.join(base_dir, event, subdir)\n",
    "            if not os.path.isdir(event_dir):\n",
    "                continue\n",
    "            for rumor in os.listdir(event_dir):\n",
    "                rumor_dir = os.path.join(event_dir, rumor)\n",
    "                source_tweet_file = os.path.join(rumor_dir, 'source-tweet', f'{rumor}.json')\n",
    "                reactions_dir = os.path.join(rumor_dir, 'reactions')\n",
    "\n",
    "                if os.path.isfile(source_tweet_file):\n",
    "                    source_tweet = read_json_file(source_tweet_file)\n",
    "                    data.append({\n",
    "                        'event': event,\n",
    "                        'tweet_id': source_tweet['id_str'],\n",
    "                        'text': source_tweet['text'],\n",
    "                        'user': source_tweet['user']['screen_name'],\n",
    "                        'timestamp': source_tweet['created_at'],\n",
    "                        'type': 'source',\n",
    "                        'is_rumour': 1 if subdir == 'rumours' else 0\n",
    "                    })\n",
    "\n",
    "                if os.path.isdir(reactions_dir):\n",
    "                    for reaction_file in os.listdir(reactions_dir):\n",
    "                        reaction_path = os.path.join(reactions_dir, reaction_file)\n",
    "                        reaction_tweet = read_json_file(reaction_path)\n",
    "                        data.append({\n",
    "                            'event': event,\n",
    "                            'tweet_id': reaction_tweet['id_str'],\n",
    "                            'text': reaction_tweet['text'],\n",
    "                            'user': reaction_tweet['user']['screen_name'],\n",
    "                            'timestamp': reaction_tweet['created_at'],\n",
    "                            'type': 'reaction',\n",
    "                            'is_rumour': 1 if subdir == 'rumours' else 0\n",
    "                        })\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83a3ffb43ed0af7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:11:42.466872Z",
     "start_time": "2024-05-22T05:10:55.965971Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pheme_df = load_pheme_dataset(pheme_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10bd37a7f63780b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:11:43.097349Z",
     "start_time": "2024-05-22T05:11:42.468881Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pheme_df.to_csv('data/csv/pheme_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c3c2372b8fed82e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:11:43.109641Z",
     "start_time": "2024-05-22T05:11:43.098357Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               event            tweet_id  \\\n",
      "0       charliehebdo  552783238415265792   \n",
      "1       charliehebdo  552787794503143424   \n",
      "2       charliehebdo  552789647966109696   \n",
      "3       charliehebdo  552791411053973505   \n",
      "4       charliehebdo  552793152390955009   \n",
      "...              ...                 ...   \n",
      "103207   sydneysiege  544526845966704641   \n",
      "103208   sydneysiege  544526940636323840   \n",
      "103209   sydneysiege  544527197810475011   \n",
      "103210   sydneysiege  544531943334100992   \n",
      "103211   sydneysiege  544535839657967616   \n",
      "\n",
      "                                                     text           user  \\\n",
      "0       Breaking: At least 10 dead, 5 injured after tO...     H_E_Samuel   \n",
      "1       @H_E_Samuel @George_Berridge @michael_taggart ...   EdwardBowden   \n",
      "2       @H_E_Samuel Hi Henry would you be willing to g...   NickyRusmith   \n",
      "3       @H_E_Samuel @H_E_Samuel please call them terro...        pravsly   \n",
      "4       @H_E_Samuel French govt needs to take strict a...      sharatsrs   \n",
      "...                                                   ...            ...   \n",
      "103207  @heyradar @MarkMcCleskey @JohnMartin929 crap, ...      Jon_Roser   \n",
      "103208                   @piiizzzzaaaa @heyradar hahahaha      Jon_Roser   \n",
      "103209  @Jon_Roser @heyradar @JohnMartin929 It's @chra...  MarkMcCleskey   \n",
      "103210  @JohnMartin929 @MarkMcCleskey @PzFeed had to b...        ldock93   \n",
      "103211  @MarkMcCleskey @Jon_Roser @heyradar @JohnMarti...         chrabe   \n",
      "\n",
      "                             timestamp      type  is_rumour  \n",
      "0       Wed Jan 07 11:06:08 +0000 2015    source          1  \n",
      "1       Wed Jan 07 11:24:15 +0000 2015  reaction          1  \n",
      "2       Wed Jan 07 11:31:37 +0000 2015  reaction          1  \n",
      "3       Wed Jan 07 11:38:37 +0000 2015  reaction          1  \n",
      "4       Wed Jan 07 11:45:32 +0000 2015  reaction          1  \n",
      "...                                ...       ...        ...  \n",
      "103207  Mon Dec 15 16:18:11 +0000 2014  reaction          0  \n",
      "103208  Mon Dec 15 16:18:34 +0000 2014  reaction          0  \n",
      "103209  Mon Dec 15 16:19:35 +0000 2014  reaction          0  \n",
      "103210  Mon Dec 15 16:38:26 +0000 2014  reaction          0  \n",
      "103211  Mon Dec 15 16:53:55 +0000 2014  reaction          0  \n",
      "\n",
      "[103212 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pheme_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
